{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FunkEngine2023/FunkEngine2023.github.io/blob/Funky_Notebooks/FunkEngineFuckery-finally.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Yihz3hAb2E"
      },
      "source": [
        "https://colab.research.google.com/github/TavernAI/TavernAI/blob/main/colab/GPU.ipynb<br>\n",
        "\n",
        "Works with:<br>\n",
        "KoboldAI https://github.com/KoboldAI/KoboldAI-Client<br>\n",
        "<br>\n",
        "**Links**<br>\n",
        "TavernAI Github https://github.com/TavernAI/TavernAI<br>\n",
        "TavernAI Discord https://discord.gg/zmK2gmr45t<br>\n",
        "TavernAI Boosty https://boosty.to/tavernai\n",
        "<pre>\n",
        " Tavern.AI/ \\ /  ^   ^ ^ ^    ~~~~ ^ \\     /  ^ ^   ^ ^/ ^  ^ \\/^  ^    \\\n",
        "         /^ ^\\ ^  ^ ^   ^ ^  ~~   ^   \\   /  ^  ^ ^   / ^ ^  ^/   ^ ^    \\\n",
        "        /^ ^ ^\\^   ^ ^ ^   _||____   ^ \\ /  ^  ^ ^   /       /  ^  ^  ^   \\\n",
        " /\\ /\\ /\\   ^  \\  /\\ /\\   /\\\\\\\\\\\\\\\\   ^ \\  ^ /\\ /\\ /\\   /\\ /\\ /\\  ^ ^  ^/\\\n",
        "//\\\\/\\\\/\\\\   ^  \\//\\\\/\\\\ /__\\\\\\\\\\\\\\\\  _, \\  //\\\\/\\\\/\\\\ //\\\\/\\\\/\\\\  ^ ^ //\\\\\n",
        "//\\\\/\\\\/\\\\       //\\\\/\\\\ |__|_|_|__|   \\__, //\\\\/\\\\/\\\\ //\\\\/\\\\/\\\\     ///\\\\\\\n",
        " || || (@＾◡＾)(≖ ‸ ≖*) ( ←_← )\\| /|   /\\ \\ヽ(°ㅂ°╬) |( Ψ▼ｰ▼)∈ (O_O; )  |||\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~ ~~~~~ ~~~~~ ~~~~~  ~~~~~ ~~ \n",
        "</pre>\n",
        "**Launch Instructions**<br>\n",
        "1. ## Horde users as well as NovelAI and OpenAI users load stupid fast now... Pick the desired endpoint from the model list to use Horde, OpenAI, or NoovelAI.\n",
        "2. ## The URL needed to access the TavernAI interface will appear essentially right away. You'll know it when it appears and can click into it right away and get it loading up in a new tab while you wait for your model to spin up. (If you're loading an actual model.) You can putz around in tavern while Kobold-AI loads the model, e.g. browse Chara Cloud, select your character, adjust your settings, etc long before the Kobold-AI link drops into the console. \n",
        "3. ## After initialization of the model the Kobold-AI link(s) to the KoboldAI UI(s) appear, for loading soft prompts, etc. YOU DO NOT NEED TO COPY AND PASTE THESE INTO TAVERN AND HAVE NOT FOR A FEW WEEKS NOW! You just can't prompt your model before they're posted to the console, which indicates loading has finished. The API URL to KoboldAI is hard-coded into this version of TavernAI and as far as this TavernAI is concerned, will ALWAYS be '127.0.0.1:5000/api' because both TavernAI and KoboldAI are running CONCURRENTLY here on the same VM right HERE in Colab. If you copy and paste the KoboldAI URL into TavernAI you're LITERALLY making everything slower and sketchier because you're sending things out onto the internet, all over the place, and eventually they come back to THE SAME MACHINE they were sent by, but to a different program, which rsponds by sending stuff back out and around all over the internet only to come back to the same place it started from.  QUIT DOING DUMB THINGS. Please!\n",
        "\n",
        "--FunkEngine\n",
        "\n",
        "**Faq**<br>\n",
        "* Q: My TavernAI link asks for an 'endpoint something or other' when I click the link, how do I get in?\n",
        "* A: To prevent redirection and reverse-proxies from being used for scamming or other nefarious purposes, currently you have to confirm the other end of the tunnel's public IP address before the link is established. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ENDPOINT!\n",
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "id": "Uci9ozd9q_B5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6kL-3-IoGCa"
      },
      "outputs": [],
      "source": [
        "#@title <h1> V-Tap this if you play on Mobile-V </h1> { vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "#Taken from KoboldAI colab\n",
        "%%html --isolated\n",
        "<audio loop autoplay src=\"https://henk.tech/colabkobold/silence.m4a\" controls></audio><br/><br/><br/><b>The silent audio track will hopefully convince your phone browser that you're listening to music, and will keep this tab active.</b><br/><br/><br/><br/><br/><br/><video src=\"https://github.com/FunkEngine2023/FunkEngine2023.github.io/raw/Funky_Notebooks/NFM.mp4\" hidden></video><br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hps3qtPLFNBb"
      },
      "outputs": [],
      "source": [
        "#@title <h1>TavernAI</h1> { vertical-output: true, form-width: \"44%\", display-mode: \"form\" }\n",
        "#@markdown # <- Click For Start (≖ ‸ ≖ ✿) NEW OPTION AVAILABLE.\n",
        "Model = \"Kobold Horde\" #@param [\"Kobold Horde\", \"NovelAI\", \"OpenAI\", \"Without Model\", \"Erebus 6B\", \"Nerybus 6B\", \"Nerys V2 6B\", \"\"] {allow-input: true}\n",
        "Version = \"Official\" \n",
        "KoboldAI_Provider = \"Cloudflare\" #@param [\"Cloudflare\"]\n",
        "#@markdown Store settings, softprompts, conversations, usercripts, preferences, and presets between sessions in Google Drive?\n",
        "#@markdown\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown This is the **normal** 'use_google_drive?' you are familiar with.\n",
        "#@markdown ##**Tl;dr: Tick the box above like it normally is.**\n",
        "#@markdown Do not confuse 'use_google_drive' with the new option to store MODELS as well, which is entirely optional. (You don't have to store your models.)\n",
        "#@markdown\n",
        "#@markdown # VVV **NEW OPTION!** VVV\n",
        "#@markdown \n",
        "#@markdown ### **REQUIRES** expanded Google Drive capacity to use!\n",
        "#@markdown\n",
        "#@markdown **Default is too small to hold even one 6b parameter model.**\n",
        "#@markdown\n",
        "#@markdown (But you can buy more storage from Google for a small fee.)\n",
        "#@markdown\n",
        "#@markdown # **If you have an expanded Google Drive already:**\n",
        "#@markdown\n",
        "#@markdown ## You can vastly reduce the wait time for loading models.\n",
        "#@markdown\n",
        "#@markdown **Enable this option** to save the model to your Google Drive.\n",
        "#@markdown\n",
        "#@markdown (Each individual model requires an average of 18GiB to store.)\n",
        "got_gigs = True #@param {type:\"boolean\"}\n",
        "#@markdown #### If you tick the got_gigs option, loaded models will be saved to your Google Drive, and loaded from there going forward.\n",
        "#@markdown\n",
        "#@markdown # **Which is 20x-30x faster.**\n",
        "#@markdown\n",
        "#@markdown ## Than downloading from hf.co over the internet every time you load an AI.\n",
        "#@markdown (Which is how 99.995% of you have been doing it all along.)\n",
        "#@markdown\n",
        "#@markdown # **Stored models can load in as little as 2m30s from pressing play to typing your first message.**\n",
        "#@markdown (If the model chosen is not on your drive, the model will be automatically downloaded as usual, but it will be saved to your Drive and load much faster every time after.)\n",
        "#@markdown\n",
        "#@markdown .\n",
        "#@markdown\n",
        "#@markdown ..\n",
        "#@markdown\n",
        "#@markdown ...\n",
        "#@markdown\n",
        "#@markdown # **I (FunkEngine) cannot effectively express with words how much better and more reliable this method is.**\n",
        "#@markdown ### Truly, I cannot understate how having more than the default 15GiB of Google Drive storage will likely improve your life...\n",
        "#@markdown\n",
        "#@markdown (USD)$1.99(+tax) a month will give you 100GiB capacity. (That's the least expensive plan available as of 2023. You can pay more to get more, but 100GiB is the smallest option.)\n",
        "#@markdown\n",
        "#@markdown (100Gib will hold ~5 models in the 6b-7b range.)\n",
        "#@markdown\n",
        "#@markdown Google One members get extra storage included as a membership perk by default.\n",
        "\n",
        "%cd /\n",
        "\n",
        "!npm install -g localtunnel\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "import threading\n",
        "#import shutil\n",
        "from google.colab import drive\n",
        "!nohup lt --port 8000 > lt.txt 2>&1 & echo -n $! > ltpid.txt\n",
        "time.sleep(1)\n",
        "lturl = open(\"lt.txt\").readline().strip().split(\"your url is: \")[1]\n",
        "print(lturl)\n",
        "ltpid = open(\"ltpid.txt\").readline()\n",
        "print(ltpid)\n",
        "!rm -rf /content/sample_data\n",
        "!rm -rf /content/.config/\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "Provider = KoboldAI_Provider\n",
        "if got_gigs:\n",
        "  Lightspeed = \"--savemodel\"\n",
        "Lightspeed = \"\"\n",
        "\n",
        "!nvidia-smi -pm 1\n",
        "!nvidia-smi -pl 69\n",
        "!nvidia-smi -c 3\n",
        "!nvidia-smi\n",
        "\n",
        "#Env\n",
        "Revision = \"\"\n",
        "colab_type = 2\n",
        "url = \"http://127.0.0.1:5000\"\n",
        "if Model == \"Kobold Horde\":\n",
        "  colab_type = 3\n",
        "  url = \"\"\n",
        "if Model == \"Without Model\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "if Model == \"OpenAI\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "if Model == \"NovelAI\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "\n",
        "%env colab=$colab_type\n",
        "\n",
        "if colab_type == 2:\n",
        "  %env colaburl=$url\n",
        "\n",
        "if use_google_drive:\n",
        "  drive.mount('/content/drive/')\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/characters/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/characters/\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/chats/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/chats/\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/User Avatars/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI/User Avatars/\")\n",
        "else:\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    os.mkdir(\"/content/drive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/\")\n",
        "\n",
        "#TavernAI\n",
        "%cd /\n",
        "!node -v\n",
        "!git clone https://github.com/TavernAI/TavernAIColab\n",
        "%cd /TavernAIColab/\n",
        "!npm install\n",
        "time.sleep(1)\n",
        "\n",
        "# FunkEngine2023 now does what he originally intended to do here, not just what was merged prematurely...\n",
        "if use_google_drive:\n",
        "  %env googledrive=2\n",
        "  print(\"TavernAI 'total user expericnce persistence' features by FunkEngine!\")\n",
        "  %cd /\n",
        "  print(\"Starting with User Avatars...\")\n",
        "  if not os.path.isdir('/content/drive/MyDrive/TavernAI/User Avatars/'):\n",
        "    print(\"Must be your first time here... Copying default avatars to start with.\")\n",
        "    !mkdir '/content/drive/MyDrive/TavernAI/User Avatars/'\n",
        "  %cd '/TavernAIColab/public/User Avatars/'\n",
        "  !cp -f -v *.* '/content/drive/MyDrive/TavernAI/User Avatars'\n",
        "  %cd '/content/drive/MyDrive/TavernAI/User Avatars/'\n",
        "  !rm -rf '/TavernAIColab/public/User Avatars/'\n",
        "  !ln -fs '/content/drive/MyDrive/TavernAI/User Avatars/' '/TavernAIColab/public/User Avatars/'\n",
        "  %cd /\n",
        "  print(\"Avatars shall persist between sessions.\")\n",
        "  if not os.path.isfile(\"/content/drive/MyDrive/TavernAI/settings.json\"):\n",
        "    print(\"First time here? Copying default settings for you so they persist when you change them...\")\n",
        "    !cp -f -p \"/TavernAIColab/public/settings.json\" \"/content/drive/MyDrive/TavernAI/settings.json\"\n",
        "    %cd /\n",
        "  if os.path.isfile(\"/content/drive/MyDrive/TavernAI/settings.json\"):\n",
        "    print(\"Linking settings from your Google Drive to be used instead of defaults.\")\n",
        "    !rm -f \"/TavernAIColab/public/settings.json\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/settings.json\" \"/TavernAIColab/public/settings.json\"\n",
        "    %cd /\n",
        "  if not os.path.isfile(\"/content/drive/MyDrive/TavernAI/config.conf\"):\n",
        "    print(\"First time here? Copying config.conf for you so you can edit it on Drive and change things like store characters as png instead of webp.\")\n",
        "    !cp -f -p \"/TavernAIColab/config.conf\" \"/content/drive/MyDrive/TavernAI/config.conf\"\n",
        "    %cd /\n",
        "  if os.path.isfile(\"/content/drive/MyDrive/TavernAI/config.conf\"):\n",
        "    print(\"Linking config.conf from your Google Drive to override defaults.\")\n",
        "    !rm -f \"/TavernAIColab/config.conf\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/config.conf\" \"/TavernAIColab/config.conf\"\n",
        "    %cd /\n",
        "  if not os.path.isdir(\"/content/drive/MyDrive/TavernAI/characters/\"):\n",
        "    print(\"First time? Transferring default characters to drive so we don't break anything.\")\n",
        "    !mkdir /content/drive/MyDrive/TavernAI/characters\n",
        "    %cd /TavernAIColab/public/characters/\n",
        "    !cp -f -v -r *.* '/content/drive/MyDrive/TavernAI/characters'\n",
        "    %cd /\n",
        "  if os.path.isdir(\"/content/drive/MyDrive/TavernAI/characters/\"):\n",
        "    print(\"Using existing characters from your Google Drive new characters will be stored there as well.\")\n",
        "    !rm -rf \"/TavernAIColab/public/characters/\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/characters/\" \"/TavernAIColab/public/characters\"\n",
        "    %cd /\n",
        "  if not os.path.isdir(\"/content/drive/MyDrive/TavernAI/chats/\"):\n",
        "    print(\"Don't you rememeber what they took from us? Setting up Google Drive to remember the past.\")\n",
        "    !mkdir /content/drive/MyDrive/TavernAI/chats\n",
        "    %cd /TavernAIColab/public/chats/\n",
        "    !cp -f -v -r *.* '/content/drive/MyDrive/TavernAI/chats'\n",
        "    %cd /\n",
        "  if os.path.isdir(\"/content/drive/MyDrive/TavernAI/chats/\"):\n",
        "    print(\"Using your conversation history from Google Drive. Always remember what they took from us!\")\n",
        "    !rm -rf \"/TavernAIColab/public/chats/\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/chats/\" \"/TavernAIColab/public/chats\"\n",
        "    %cd /\n",
        "  if not os.path.isdir(\"/content/drive/MyDrive/TavernAI/backgrounds\"):\n",
        "    print(\"I've heard talk that backgrounds are an extremely super important to some of you...\")\n",
        "    !mkdir /content/drive/MyDrive/TavernAI/backgrounds\n",
        "    %cd /TavernAIcolab/public/backgrounds/\n",
        "    !cp -f -v -r *.* '/content/drive/MyDrive/TavernAI/backgrounds'\n",
        "    %cd /\n",
        "  if os.path.isdir(\"/content/drive/MyDrive/TavernAI/backgrounds\"):\n",
        "    print(\"I suppose we can bring the scenery along as well...\")\n",
        "    print(\"'Some of you seem oddly passionate about your custom backgrounds...' --FunkEngine Spring of 2023.\")\n",
        "    !rm -rf \"/TavernAIColab/public/backgrounds/\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/backgrounds/\" \"/TavernAIColab/public/backgrounds\"\n",
        "    print(\"Background storage linked!\")\n",
        "  print(\"That should be everything set up the way it was before...\")\n",
        "print(\"TavernAI user experience continuity is implied but not guaranteed.\")\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "# Are we loading models? If we are...\n",
        "# KoboldAI gets the console and drives\n",
        "# TavernAI gets nohupped into the back of the van.\n",
        "if colab_type == 2:\n",
        "  if Model == \"Nerys V2 6B\":\n",
        "    Model = \"KoboldAI/OPT-6B-nerys-v2\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  elif Model == \"Nerybus 6B\":\n",
        "    Model = \"KoboldAI/OPT-6.7B-Nerybus-Mix\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  elif Model == \"Erebus 6B\":\n",
        "    Model = \"KoboldAI/OPT-6.7B-Erebus\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  %cd /TavernAIColab/\n",
        "  !nohup node server.js > tai.txt 2>&1 & echo -n $! > taipid.txt\n",
        "  time.sleep(6)\n",
        "  taiurl = open(\"tai.txt\")\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  taiurl.close()\n",
        "  print(\"That is not your link.\")\n",
        "  print(\"But it means your Tavern is spinning up.\")\n",
        "  print(\"Soon.(tm)\")\n",
        "  taipid = open(\"taipid.txt\").readline()\n",
        "  print(taipid)\n",
        "  %cd /content/\n",
        "  !wget https://koboldai.org/ckds -O - | bash /dev/stdin --init only --model $Model -g United $Lightspeed --colab\n",
        "  print(\"KoboldAI prepped and ready to load the model!\")\n",
        "  print(\"TavernAI is running.\")\n",
        "  print(\"Launching KoboldAI Now to load your selected model.\")\n",
        "  print(\"Click your TavernAI link and enter the IP if/when asked.\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(lturl)\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"I cannot be accused of not pointing out how fully loaded and ready TavernAI is. You should go there now.\")\n",
        "  print(\"Handing the console off to KoboldAI now, don't worry about 'attention' and 'padding' token errors.\")\n",
        "  print(\"They're prefectly normal, there's nothing you can do about them, and they have always been there you've just never been able to see them.\")\n",
        "  %cd /content/KoboldAI-Client/\n",
        "  !python3 aiserver.py --model $Model $Lightspeed --colab\n",
        "\n",
        "#No need for KoboldAI. We give TavernAI the keys to the console!\n",
        "if colab_type != 2:\n",
        "  print(\"You selected Horde, Without Model, NovelAI or OpenAI from the menu.\")\n",
        "  print(\"Tavern is installed and set to use your settings, characters, chats, avatars, etc from Google Drive.\")\n",
        "  print(\"Here's your TavernAI link and the endpoint IP to give if/when asked to do so.\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(lturl)\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"Handing the console off to TavernAI now.\")\n",
        "  print(\"Do not be frightened. If you don't know what you're looking at, that's fine.\")\n",
        "  print(\"Just watch the pretty colors scroll by as you interact with your characters.\")\n",
        "  print(\"But at least now you can see if an error occurs and things stop working suddenly.\")\n",
        "  print(\"--Funkengine\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HTML\n",
        "from IPython.display import HTML\n",
        "HTML('<video autoplay=\"\" src=\"https://github.com/FunkEngine2023/FunkEngine2023.github.io/raw/Funky_Notebooks/VNFM.mp4\"></video>')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mb-Nc7xp20Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "import atexit\n",
        "import requests\n",
        "import subprocess\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import platform\n",
        "import time\n",
        "import re\n",
        "from random import randint\n",
        "from threading import Timer\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _run_cloudflared(port, metrics_port):\n",
        "    system, machine = platform.system(), platform.machine()\n",
        "    command = _get_command(system, machine)\n",
        "    cloudflared_path = str(Path(tempfile.gettempdir()))\n",
        "    if system == \"Darwin\":\n",
        "        _download_cloudflared(cloudflared_path, \"cloudflared-darwin-amd64.tgz\")\n",
        "        _extract_tarball(cloudflared_path, \"cloudflared-darwin-amd64.tgz\")\n",
        "    else:\n",
        "        _download_cloudflared(cloudflared_path, command)\n",
        "\n",
        "    executable = str(Path(cloudflared_path, command))\n",
        "    os.chmod(executable, 0o777)\n",
        "\n",
        "    if system == \"Darwin\" and machine == \"arm64\":\n",
        "        cloudflared = subprocess.Popen(['arch', '-x86_64', executable, 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "    else:\n",
        "        cloudflared = subprocess.Popen([executable, 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "\n",
        "    atexit.register(cloudflared.terminate)\n",
        "    localhost_url = f\"http://127.0.0.1:{metrics_port}/metrics\"\n",
        "\n",
        "    for _ in range(10):\n",
        "        try:\n",
        "            tunnel_url = requests.get(localhost_url).text\n",
        "            tunnel_url = (re.search(\"(?P<url>https?:\\/\\/[^\\s]+.trycloudflare.com)\", tunnel_url).group(\"url\"))\n",
        "            break\n",
        "        except:\n",
        "            time.sleep(3)\n",
        "    else:\n",
        "        raise Exception(f\"! Can't connect to Cloudflare Edge\")\n",
        "\n",
        "    return tunnel_url\n",
        "\n",
        "def Funnel():\n",
        "  cloudflared_address = _run_cloudflared(port, metrics_port)\n",
        "  print(f\" * Running on {cloudflared_address}\")\n",
        "  print(f\" * Traffic stats available on http://127.0.0.1:{metrics_port}/metrics\")\n",
        "\n",
        "def Exfiltrate():\n",
        "  port = 8000\n",
        "  metrics_port = 31337\n",
        "  # Starting the Cloudflared tunnel in a separate thread.\n",
        "  thread = Timer(2, Funnel, args=(8000, 31337,))\n",
        "  thread.setDaemon(True)\n",
        "  thread.start()\n",
        "  # Running the Flask app.\n",
        "\n",
        "\n",
        "Exfiltrate()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xSCMnQ6rQXKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%cd /content/\n",
        "import os\n",
        "import subprocess\n",
        "import requests\n",
        "import atexit\n",
        "import time\n",
        "from threading import Timer\n",
        "import re\n",
        "\n",
        "if not os.path.isfile('/content/cloudflared-linux-amd64'):\n",
        "  !wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "  print(\"Getting it!\")\n",
        "print(\"Has it!\")\n",
        "\n",
        "os.chmod('/content/cloudflared-linux-amd64', 0o777)\n",
        "\n",
        "def TunnelFunk():\n",
        "  EngineTunnel = subprocess.Popen(['cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --metrics 127.0.0.1:31337'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "  atexit.register(EngineTunnel.terminate)\n",
        "  localhost_url = \"http://127.0.0.1:31337/metrics\"\n",
        "  for _ in range(10):\n",
        "    try:\n",
        "      tunnel_str = requests.get(localhost_url).text\n",
        "      tunnel_url = re.search(\"(?P<url>https?://[^ ]+.trycloudflare.com)\", tunnel_str)\n",
        "      if tunnel_url is not None:\n",
        "        print(tunnel_url.group(\"url\"))\n",
        "        funnelurl = tunnel_url\n",
        "        break\n",
        "    except:\n",
        "      time.sleep(3)\n",
        "  else:\n",
        "    raise Exception(\"! Can't connect to Cloudflare Edge\")\n",
        "  return tunnel_url\n",
        "\n",
        "\n",
        "\n",
        "def TunnelEngine():\n",
        "    EngineFunk = TunnelFunk()\n",
        "    print(tunnel_url)\n",
        "    print(\"http://127.0.0.1:31337/metrics\")\n",
        "\n",
        "\n",
        "\n",
        "def FunkTunnel():\n",
        "  thread = Timer(2, TunnelEngine, args=())\n",
        "  thread.setDaemon(True)\n",
        "  thread.start()\n",
        "FunkTunnel.run = FunkTunnel"
      ],
      "metadata": {
        "id": "SAont2TqIB-5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%cd /content/\n",
        "import os\n",
        "import subprocess\n",
        "import requests\n",
        "import atexit\n",
        "import time\n",
        "from threading import Timer\n",
        "import re\n",
        "\n",
        "port = '8000'\n",
        "metrics_port = '31337'\n",
        "\n",
        "from flask_cloudflared import _run_cloudflared\n",
        "if port == 8000:\n",
        "  %sc -v cloudflare=_run_cloudflared('8000', '31337')\n",
        "  cloudflare_link = cloudflare\n",
        "  if port == 8000:\n",
        "    with open('cloudflare.log', 'w') as cloudflarelog:\n",
        "      cloudflarelog.write(\"KoboldAI has finished loading and is available at the following link : \" + cloudflare)\n",
        "      print(\"Webserver\")\n",
        "      if port ==8000:\n",
        "        # If we're using a TPU our UI will freeze during the connection to the TPU. To prevent this from showing to the user we \n",
        "        # delay the display of this message until after that step\n",
        "        print(\"KoboldAI has finished loading and is available at the following link for UI 1: \")\n",
        "        print(\"KoboldAI has finished loading and is available at the following link for UI 2: /new_ui\")\n",
        "  else:\n",
        "    print(\"Webserver OK\")\n",
        "    print(\"Webserver has started, you can now connect to this machine at x.\")\n",
        "  serverstarted = True\n",
        "  if port == 8000:\n",
        "    print(\"app, port=port, host='0.0.0.0'\")\n",
        "  else:\n",
        "    print(\"app, port=port\")\n",
        "else:\n",
        "  if port == 8000:\n",
        "    if port == 8000:\n",
        "      try:\n",
        "        import webbrowser\n",
        "        webbrowser.open_new('http://localhost:{0}'.format(port))\n",
        "      except:\n",
        "        pass\n",
        "    print(\"Webserver OK\")\n",
        "    print(\"Webserver started! You may now connect with a browser at http://127.0.0.1:{port}\")\n",
        "    serverstarted = True\n",
        "    print(\"app, port=port, host='0.0.0.0'\")\n",
        "  else:\n",
        "    if port == 8000:\n",
        "      try:\n",
        "        import webbrowser\n",
        "        webbrowser.open_new('http://localhost:{0}'.format(port))\n",
        "      except:\n",
        "        pass\n",
        "    print(\"Webserver OK\")\n",
        "    print(\"Webserver started! You may now connect with a browser at http://127.0.0.1:{port}\")\n",
        "    serverstarted = True\n",
        "    print(\"app, port=port\")\n",
        "    print(\"Webserver Closed\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fXalGDRWjw1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install flask-cloudflared"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yEwc_eYeeNxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#line='cloudflared_tunnel_user_hostnames_counts{userHostname=\"https://toy-authorization-cinema-vista.trycloudflare.com\"} 1'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-6rdmmVvWTOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import atexit\n",
        "import requests\n",
        "import subprocess\n",
        "import tarfile\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import platform\n",
        "import time\n",
        "import re\n",
        "from random import randint\n",
        "from threading import Timer\n",
        "from pathlib import Path\n",
        "\n",
        "CLOUDFLARED_CONFIG = {\n",
        "    ('Windows', 'AMD64'): {\n",
        "        'command': 'cloudflared-windows-amd64.exe',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-windows-amd64.exe'\n",
        "    },\n",
        "    ('Windows', 'x86'): {\n",
        "        'command': 'cloudflared-windows-386.exe',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-windows-386.exe'\n",
        "    },\n",
        "    ('Linux', 'x86_64'): {\n",
        "        'command': 'cloudflared-linux-amd64',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64'\n",
        "    },\n",
        "    ('Linux', 'i386'): {\n",
        "        'command': 'cloudflared-linux-386',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-386'\n",
        "    },\n",
        "    ('Linux', 'arm'): {\n",
        "        'command': 'cloudflared-linux-arm',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-arm'\n",
        "    },\n",
        "    ('Linux', 'arm64'): {\n",
        "        'command': 'cloudflared-linux-arm64',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-arm64'\n",
        "    },\n",
        "    ('Linux', 'aarch64'): {\n",
        "        'command': 'cloudflared-linux-arm64',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-arm64'\n",
        "    },\n",
        "    ('Darwin', 'x86_64'): {\n",
        "        'command': 'cloudflared',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-darwin-amd64.tgz'\n",
        "    },\n",
        "    ('Darwin', 'arm64'): {\n",
        "        'command': 'cloudflared',\n",
        "        'url': 'https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-darwin-amd64.tgz'\n",
        "    }\n",
        "}\n",
        "\n",
        "funk=True\n",
        "\n",
        "def _get_command(system, machine):\n",
        "    try:\n",
        "        return CLOUDFLARED_CONFIG[(system, machine)]['command']\n",
        "    except KeyError:\n",
        "        raise Exception(f\"{machine} is not supported on {system}\")\n",
        "\n",
        "def _get_url(system, machine):\n",
        "    try:\n",
        "        return CLOUDFLARED_CONFIG[(system, machine)]['url']\n",
        "    except KeyError:\n",
        "        raise Exception(f\"{machine} is not supported on {system}\")\n",
        "\n",
        "def _download_cloudflared(cloudflared_path, command):\n",
        "    system, machine = platform.system(), platform.machine()\n",
        "    if Path(cloudflared_path, command).exists():\n",
        "        executable = (cloudflared_path+'/'+'cloudflared') if (system == \"Darwin\" and machine in [\"x86_64\", \"arm64\"]) else (cloudflared_path+'/'+command)\n",
        "        update_cloudflared = subprocess.Popen([executable, 'update'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "        return\n",
        "    print(f\" * Downloading cloudflared for {system} {machine}...\")\n",
        "    url = _get_url(system, machine)\n",
        "    _download_file(url)\n",
        "\n",
        "def _download_file(url):\n",
        "    local_filename = url.split('/')[-1]\n",
        "    r = requests.get(url, stream=True)\n",
        "    download_path = str(Path(tempfile.gettempdir(), local_filename))\n",
        "    with open(download_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    return download_path\n",
        "\n",
        "def _run_cloudflared(port, metrics_port):\n",
        "    system, machine = platform.system(), platform.machine()\n",
        "    command = _get_command(system, machine)\n",
        "    cloudflared_path = str(Path(tempfile.gettempdir()))\n",
        "    _download_cloudflared(cloudflared_path, command)\n",
        "\n",
        "    executable = str(Path(cloudflared_path, command))\n",
        "    os.chmod(executable, 0o777)\n",
        "\n",
        "    if system == \"Darwin\" and machine == \"arm64\":\n",
        "        cloudflared = subprocess.Popen(['arch', '-x86_64', executable, 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "    else:\n",
        "        cloudflared = subprocess.Popen([executable, 'tunnel', '--url', f'http://127.0.0.1:{port}', '--metrics', f'127.0.0.1:{metrics_port}'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "\n",
        "    atexit.register(cloudflared.terminate)\n",
        "    localhost_url = f\"http://127.0.0.1:{metrics_port}/metrics\"\n",
        "\n",
        "    for _ in range(10):\n",
        "        try:\n",
        "            tunnel_url = requests.get(localhost_url).text\n",
        "            tunnel_url = re.search(\"(?P<url>https?://[^ ]+.trycloudflare.com)\", tunnel_url)\n",
        "            if tunnel_url is not None:\n",
        "              print(tunnel_url.group(\"url\"))\n",
        "            break\n",
        "        except:\n",
        "            time.sleep(3)\n",
        "    else:\n",
        "        raise Exception(f\"! Can't connect to Cloudflare Edge\")\n",
        "\n",
        "    return tunnel_url\n",
        "\n",
        "def start_cloudflared(port, metrics_port):\n",
        "    cloudflared_address = _run_cloudflared(port, metrics_port)\n",
        "    print(f\" * Running on {cloudflared_address}\")\n",
        "    print(f\" * Traffic stats available on http://127.0.0.1:{metrics_port}/metrics\")\n",
        "\n",
        "def run_with_cloudflared(funk):\n",
        "    old_run=funk.run\n",
        "\n",
        "    def new_run(*args, **kwargs):\n",
        "        # Webserver port is 5000 by default.\n",
        "        port = '8000'\n",
        "        # If metrics_port is not specified, we will use a random port between 8100 and 9000.\n",
        "        metrics_port = '31337'\n",
        "        # Removing the port and metrics_port from kwargs to avoid passing them to the Flask app.\n",
        "        # kwargs.pop('metrics_port', None)\n",
        "        # Starting the Cloudflared tunnel in a separate thread.\n",
        "        thread = Timer(2, start_cloudflared, args=(port, metrics_port,))\n",
        "        thread.setDaemon(True)\n",
        "        thread.start()\n",
        "        # Running the Flask app.\n",
        "        old_run=funk.run\n",
        "    new_run(funk)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RGzSXd4yxvm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!cp /root/.tmux.conf /content/\n",
        "\n",
        "subprocess.Popen(['cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --metrics 127.0.0.1:31337'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "http://127.0.0.1:31337/metrics\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9xJgnMvJCqJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!ps -ef -w"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jFwrKdrQb3yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%cd /content\n",
        "if not os.path.isfile('/content/cloudflared-linux-amd64'):\n",
        "  !wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "  print(\"Getting it!\")\n",
        "print(\"Has it!\")\n",
        "time.sleep(4)\n",
        "os.chmod('/content/cloudflared-linux-amd64', 0o777)\n",
        "subprocess.Popen(['/content/cloudflared-linux-amd64', 'tunnel', '--url', 'http://127.0.0.1:8000', '--metrics', '127.0.0.1:31337'], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
        "print(\"Maybe?\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FTanW5saThjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import requests\n",
        "import subprocess\n",
        "import os\n",
        "scrape = requests.get('http://127.0.0.1:31337/metrics').text\n",
        "haystack = scrape.partition('cloudflared_tunnel_user_hostnames_counts{userHostname=\"')[2]\n",
        "needle = haystack.split('\"} 1')[0]\n",
        "print(needle)\n",
        "%cd /content/\n",
        "if needle != '':\n",
        "  cloudflarelog = open('cloudflare.log', 'w')\n",
        "  cloudflarelog.write(\"CLOUDFLARE PROVIDES!\" + needle)\n",
        "  cloudflarelog.close()\n",
        "  print(\"HERE'S YOUR LINK!\" + needle)\n",
        "print(\"Way harder than it needed to be...\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jq_1WxwIAJ6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!ps -ef -w"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AYRIOgF-hObz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!curl ipecho.net/plain"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ngqSDViEhh6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!sudo lsof -i -P -n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CtDyFbuZhtGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "d-Yihz3hAb2E"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}